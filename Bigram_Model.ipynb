{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e61e3ed-7f31-42f6-9bb5-6bb3d9354193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ccf4602-3421-450c-90f6-eb1222eef74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "127f2165-bb03-4bac-8ff5-f4411d31639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability Look Up table for the next probable character\n",
    "\n",
    "N = torch.ones((27, 27), dtype=torch.int32)  # Initializing the N matrix from 1, so that while calculating for loss it won't be infinity (loss = log likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "363ecfd1-7601-4a1f-b770-edfee7c729a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All unique characters\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "\n",
    "# Numbering all the characters from 1-26\n",
    "\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b79a6067-d513-469b-b500-dcdb7605fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = {i:s for s, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f89f0e8b-4378-4f13-b134-91e94ca140bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    word = ['.']+list(word)+['.']\n",
    "    for ch1, ch2 in zip(word, word[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa097aa7-bbb2-4408-acc2-a3788d6c24c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "# Normalizing the N matrix\n",
    "\n",
    "p = N.float()\n",
    "p = p/p.sum(dim=1, keepdims=True)  # Across the row now gives the probability of the next word given first word, sum across the row is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "309450a3-fc35-4579-b6f1-5fa73ee5ad98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.4599e-02, 5.0359e-01, 6.8329e-04, 1.7082e-03, 1.7082e-03, 1.5067e-01,\n",
       "        3.4165e-04, 3.4165e-04, 1.5716e-02, 4.0998e-02, 1.0249e-03, 1.0249e-03,\n",
       "        3.4165e-03, 2.0499e-03, 1.0249e-03, 1.6399e-01, 6.8329e-04, 3.4165e-04,\n",
       "        4.0998e-03, 2.7332e-03, 1.0249e-03, 6.9354e-02, 2.0499e-03, 2.3915e-03,\n",
       "        3.4165e-04, 3.7581e-03, 3.4165e-04])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 10\n",
    "itos[ix]\n",
    "p[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "770977f2-a80b-4989-bbe2-acf02344ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "\n",
    "names = []\n",
    "for i in range(10):\n",
    "    ix = 16\n",
    "    name = itos[ix]\n",
    "    while True:\n",
    "        ix = torch.multinomial(p[ix], num_samples=1, replacement=True, generator=g).item()\n",
    "        name += itos[ix]\n",
    "        if ix == 0:\n",
    "            break\n",
    "    names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8cecf564-7748-471e-8541-ec2a377df392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pa.',\n",
       " 'ponde.',\n",
       " 'pianasah.',\n",
       " 'pp.',\n",
       " 'pelay.',\n",
       " 'pe.',\n",
       " 'pria.',\n",
       " 'pohin.',\n",
       " 'ptolian.',\n",
       " 'patee.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f951dd7c-07e0-4de4-8640-b433a75b98da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4544)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss Estimation\n",
    "\n",
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "for word in words:\n",
    "    word = ['.']+list(word)+['.']\n",
    "    for ch1, ch2, in zip(word, word[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = p[ix1, ix2]\n",
    "        log_likelihood += torch.log(prob)\n",
    "        n += 1\n",
    "\n",
    "log_likelihood\n",
    "negative_log_likelihood = -1*log_likelihood\n",
    "normalized_nll = negative_log_likelihood/n\n",
    "normalized_nll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff838e20-0083-407a-83aa-aec5dc97ed1e",
   "metadata": {},
   "source": [
    "The Same done by A Single Layer Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "556a7cd9-2267-45d1-a248-c4a66e3869e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "713fe8ab-3034-43bd-9b13-abdbc762e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset for the Neural Network\n",
    "\n",
    "xs, ys = [], []\n",
    "for word in words:\n",
    "    word = ['.']+list(word)+['.']\n",
    "    for ch1, ch2 in zip(word, word[1:]):\n",
    "        ix = stoi[ch1]\n",
    "        iy = stoi[ch2]\n",
    "        xs.append(ix)\n",
    "        ys.append(iy)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3cb49d07-7f57-4089-b74f-3d4054f331bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 27])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_encoded = F.one_hot(xs, num_classes=27).float()\n",
    "xs_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e024d3da-5e41-48c7-882f-4dbf80a9c875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 0th iteration is, 3.750535488128662\n",
      "Loss after 1th iteration is, 3.1274166107177734\n",
      "Loss after 2th iteration is, 2.964362382888794\n",
      "Loss after 3th iteration is, 2.7907614707946777\n",
      "Loss after 4th iteration is, 2.7167773246765137\n",
      "Loss after 5th iteration is, 2.6727962493896484\n",
      "Loss after 6th iteration is, 2.6580452919006348\n",
      "Loss after 7th iteration is, 2.6278903484344482\n",
      "Loss after 8th iteration is, 2.629685163497925\n",
      "Loss after 9th iteration is, 2.6292243003845215\n",
      "Loss after 10th iteration is, 2.60052752494812\n",
      "Loss after 11th iteration is, 2.5971646308898926\n",
      "Loss after 12th iteration is, 2.5866198539733887\n",
      "Loss after 13th iteration is, 2.6072535514831543\n",
      "Loss after 14th iteration is, 2.5684993267059326\n",
      "Loss after 15th iteration is, 2.5703651905059814\n",
      "Loss after 16th iteration is, 2.6075854301452637\n",
      "Loss after 17th iteration is, 2.6255831718444824\n",
      "Loss after 18th iteration is, 2.5490593910217285\n",
      "Loss after 19th iteration is, 2.532025098800659\n",
      "Loss after 20th iteration is, 2.5565884113311768\n",
      "Loss after 21th iteration is, 2.5424296855926514\n",
      "Loss after 22th iteration is, 2.6022815704345703\n",
      "Loss after 23th iteration is, 2.5191023349761963\n",
      "Loss after 24th iteration is, 2.5370514392852783\n",
      "Loss after 25th iteration is, 2.5481252670288086\n",
      "Loss after 26th iteration is, 2.606562852859497\n",
      "Loss after 27th iteration is, 2.534057855606079\n",
      "Loss after 28th iteration is, 2.525543689727783\n",
      "Loss after 29th iteration is, 2.521733283996582\n",
      "Loss after 30th iteration is, 2.556915760040283\n",
      "Loss after 31th iteration is, 2.564305067062378\n",
      "Loss after 32th iteration is, 2.6029717922210693\n",
      "Loss after 33th iteration is, 2.5036094188690186\n",
      "Loss after 34th iteration is, 2.517503023147583\n",
      "Loss after 35th iteration is, 2.506146192550659\n",
      "Loss after 36th iteration is, 2.5294034481048584\n",
      "Loss after 37th iteration is, 2.559487819671631\n",
      "Loss after 38th iteration is, 2.528517246246338\n",
      "Loss after 39th iteration is, 2.52809739112854\n",
      "Loss after 40th iteration is, 2.5709726810455322\n",
      "Loss after 41th iteration is, 2.5911827087402344\n",
      "Loss after 42th iteration is, 2.5167226791381836\n",
      "Loss after 43th iteration is, 2.5022976398468018\n",
      "Loss after 44th iteration is, 2.531616687774658\n",
      "Loss after 45th iteration is, 2.516191244125366\n",
      "Loss after 46th iteration is, 2.583951234817505\n",
      "Loss after 47th iteration is, 2.501553773880005\n",
      "Loss after 48th iteration is, 2.5162243843078613\n",
      "Loss after 49th iteration is, 2.5293362140655518\n",
      "Loss after 50th iteration is, 2.5683987140655518\n",
      "Loss after 51th iteration is, 2.5128207206726074\n",
      "Loss after 52th iteration is, 2.5336523056030273\n",
      "Loss after 53th iteration is, 2.543905735015869\n",
      "Loss after 54th iteration is, 2.603142261505127\n",
      "Loss after 55th iteration is, 2.5025579929351807\n",
      "Loss after 56th iteration is, 2.515155553817749\n",
      "Loss after 57th iteration is, 2.511749029159546\n",
      "Loss after 58th iteration is, 2.5296521186828613\n",
      "Loss after 59th iteration is, 2.547839641571045\n",
      "Loss after 60th iteration is, 2.5087203979492188\n",
      "Loss after 61th iteration is, 2.499551296234131\n",
      "Loss after 62th iteration is, 2.5233025550842285\n",
      "Loss after 63th iteration is, 2.558985948562622\n",
      "Loss after 64th iteration is, 2.5132195949554443\n",
      "Loss after 65th iteration is, 2.5014138221740723\n",
      "Loss after 66th iteration is, 2.5544071197509766\n",
      "Loss after 67th iteration is, 2.5767605304718018\n",
      "Loss after 68th iteration is, 2.511699676513672\n",
      "Loss after 69th iteration is, 2.493293523788452\n",
      "Loss after 70th iteration is, 2.51518177986145\n",
      "Loss after 71th iteration is, 2.4990036487579346\n",
      "Loss after 72th iteration is, 2.5252504348754883\n",
      "Loss after 73th iteration is, 2.5116262435913086\n",
      "Loss after 74th iteration is, 2.556260585784912\n",
      "Loss after 75th iteration is, 2.494725465774536\n",
      "Loss after 76th iteration is, 2.5190563201904297\n",
      "Loss after 77th iteration is, 2.5081841945648193\n",
      "Loss after 78th iteration is, 2.565107822418213\n",
      "Loss after 79th iteration is, 2.4882376194000244\n",
      "Loss after 80th iteration is, 2.5107667446136475\n",
      "Loss after 81th iteration is, 2.517411708831787\n",
      "Loss after 82th iteration is, 2.599820137023926\n",
      "Loss after 83th iteration is, 2.5246002674102783\n",
      "Loss after 84th iteration is, 2.50429368019104\n",
      "Loss after 85th iteration is, 2.5009512901306152\n",
      "Loss after 86th iteration is, 2.524806261062622\n",
      "Loss after 87th iteration is, 2.580345630645752\n",
      "Loss after 88th iteration is, 2.5329678058624268\n",
      "Loss after 89th iteration is, 2.4873926639556885\n",
      "Loss after 90th iteration is, 2.5076920986175537\n",
      "Loss after 91th iteration is, 2.5003628730773926\n",
      "Loss after 92th iteration is, 2.55385422706604\n",
      "Loss after 93th iteration is, 2.492546796798706\n",
      "Loss after 94th iteration is, 2.533777952194214\n",
      "Loss after 95th iteration is, 2.5326595306396484\n",
      "Loss after 96th iteration is, 2.5888335704803467\n",
      "Loss after 97th iteration is, 2.4960434436798096\n",
      "Loss after 98th iteration is, 2.5055201053619385\n",
      "Loss after 99th iteration is, 2.497349500656128\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(32)\n",
    "\n",
    "# Weight Initialization\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)\n",
    "ls = []\n",
    "for k in range(100):\n",
    "    # Forward Pass\n",
    "    xs_encoded @ W\n",
    "    r = (xs_encoded @ W).exp()\n",
    "    probs = r/r.sum(dim=1, keepdims=True)\n",
    "\n",
    "    # Loss\n",
    "    loss = -1*probs[torch.arange(228146), ys].log().mean() + 0.001 * (W**2).mean()  # Regularization loss with 0.001 regularization strength\n",
    "    ls.append(loss)\n",
    "    print(f'Loss after {k}th iteration is, {loss}')\n",
    "\n",
    "    # Backward Pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    W.data += -120 * W.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f11d80-eea8-405b-af19-618705893637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
